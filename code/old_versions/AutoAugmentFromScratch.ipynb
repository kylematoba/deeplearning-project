{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoAugmentFromScratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "QoQlpJVkodPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5165722-cb5f-48a0-a486-259e37c81d67"
      },
      "cell_type": "code",
      "source": [
        "from keras import models, layers, backend, initializers\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "es9Jqg1YtaZ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This section is temporarily taken from RPMCruz, and \n",
        "we'll want to revisit them when we focus on the whole set of transforms\n",
        "https://github.com/rpmcruz/autoaugment\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import PIL\n",
        "import PIL, PIL.ImageOps, PIL.ImageEnhance, PIL.ImageDraw\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def ShearX(img, v):  # [-0.3, 0.3]\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
        "\n",
        "def ShearY(img, v):  # [-0.3, 0.3]\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
        "\n",
        "def TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
        "    v = v*img.size[0]\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
        "\n",
        "def TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
        "    v = v*img.size[1]\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
        "\n",
        "def Rotate(img, v):  # [-30, 30]\n",
        "    return img.rotate(v)\n",
        "\n",
        "def AutoContrast(img, _):\n",
        "    return PIL.ImageOps.autocontrast(img)\n",
        "\n",
        "def Invert(img, _):\n",
        "    return PIL.ImageOps.invert(img)\n",
        "\n",
        "def Equalize(img, _):\n",
        "    return PIL.ImageOps.equalize(img)\n",
        "\n",
        "def Flip(img, _):  # not from the paper\n",
        "    return PIL.ImageOps.mirror(img)\n",
        "\n",
        "def Solarize(img, v):  # [0, 256]\n",
        "    return PIL.ImageOps.solarize(img, v)\n",
        "\n",
        "def Posterize(img, v):  # [4, 8]\n",
        "    v = int(v)\n",
        "    return PIL.ImageOps.posterize(img, v)\n",
        "\n",
        "def Contrast(img, v):  # [0.1,1.9]\n",
        "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
        "\n",
        "def Color(img, v):  # [0.1,1.9]\n",
        "    return PIL.ImageEnhance.Color(img).enhance(v)\n",
        "\n",
        "def Brightness(img, v):  # [0.1,1.9]\n",
        "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
        "\n",
        "def Sharpness(img, v):  # [0.1,1.9]\n",
        "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
        "\n",
        "def Cutout(img, v):  # [0, 60] => percentage: [0, 0.2]\n",
        "    w, h = img.size\n",
        "    v = v*img.size[0]\n",
        "    x0 = np.random.uniform(w-v)\n",
        "    y0 = np.random.uniform(h-v)\n",
        "    xy = (x0, y0, x0+v, y0+v)\n",
        "    color = (127, 127, 127)\n",
        "    img = img.copy()\n",
        "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
        "    return img\n",
        "\n",
        "  \n",
        "# JG - Removed this one for simplicity, as it was the only operation\n",
        "# that required passing multiple images\n",
        "# We might want to add it back later\n",
        "\n",
        "# def SamplePairing(imgs):  # [0, 0.4]\n",
        "#     def f(img1, v):\n",
        "#         i = np.random.choice(len(imgs))\n",
        "#         img2 = PIL.Image.fromarray(imgs[i])\n",
        "#         return PIL.Image.blend(img1, img2, v)\n",
        "#     return f\n",
        "\n",
        "def getTransformations():\n",
        "    return [\n",
        "        (ShearX, -0.3, 0.3),\n",
        "        (ShearY, -0.3, 0.3),\n",
        "        (TranslateX, -0.45, 0.45),\n",
        "        (TranslateY, -0.45, 0.45),\n",
        "        (Rotate, -30, 30),\n",
        "        (AutoContrast, 0, 1),\n",
        "        (Invert, 0, 1),\n",
        "        (Equalize, 0, 1),\n",
        "        (Solarize, 0, 256),\n",
        "        (Posterize, 4, 8),\n",
        "        (Contrast, 0.1, 1.9),\n",
        "        (Color, 0.1, 1.9),\n",
        "        (Brightness, 0.1, 1.9),\n",
        "        (Sharpness, 0.1, 1.9),\n",
        "        (Cutout, 0, 0.2),\n",
        "#         (SamplePairing(imgs), 0, 0.4),\n",
        "    ]\n",
        "transformations = getTransformations()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zO6L6PkNplFa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class Operation():\n",
        "  def __init__(self,\n",
        "               transformFunction,\n",
        "               probability,\n",
        "               magnitude):\n",
        "    \"\"\"\n",
        "    Args: \n",
        "      transformFunction: a function that takes a list of np arrays and a \n",
        "        magnitude value, and returns a list of the same length in which each\n",
        "        np array that has been transformed\n",
        "        \n",
        "      probability: float between 0 and 1. When this operation is called,\n",
        "        there is a [probability] chance of applying transformFunction, so\n",
        "        a probability of 0 indicates the transformFunction is never called\n",
        "        \n",
        "      magnitude: float to pass to the transformFunction when this Operation is \n",
        "        called\n",
        "    \"\"\"\n",
        "    \n",
        "    assert (probability >= 0.0) and (probability <= 1.0)\n",
        "    \n",
        "    self.transformFunction = transformFunction\n",
        "    self.probability = probability\n",
        "    self.magnitude = magnitude\n",
        "    self.transformName = str(transformFunction).split(' ')[1]\n",
        "    \n",
        "  def __call__(self, X):\n",
        "    \"\"\"\n",
        "    Takes a list of numpy arrays, and one at a time:\n",
        "      converts to PIL image\n",
        "      With self.probability chance, apply self.transformFunction\n",
        "      with magnitude self.magnitude.\n",
        "    Converts back to numpy array\n",
        "    Returns the new list of np.arrays\n",
        "    \"\"\"\n",
        "    transformed = []\n",
        "    for x in X:\n",
        "      pilX = PIL.Image.fromarray(x)\n",
        "      if np.random.rand() < self.probability:\n",
        "        pilX = self.transformFunction(pilX, self.magnitude)\n",
        "      transformed.append(np.array(pilX))\n",
        "    return np.array(transformed)\n",
        "  \n",
        "  def __str__(self):\n",
        "    return '%s (P=%.3f, M=%.3f)' % (self.transformName,\n",
        "                                    self.probability,\n",
        "                                    self.magnitude)\n",
        "  \n",
        "class Subpolicy():\n",
        "  def __init__(self, operations):\n",
        "    self.operations = operations\n",
        "  \n",
        "  def __call__(self, X):\n",
        "    for operation in self.operations:\n",
        "      X = operation(X)\n",
        "    return X\n",
        "  \n",
        "  def __str__(self):\n",
        "    s = ''\n",
        "    for op in self.operations:\n",
        "      s += str(op)\n",
        "      s += '\\n'\n",
        "    return s[:-1]\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4RRPV362sYBx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import models, layers, initializers\n",
        "import tensorflow as tf\n",
        "\n",
        "    \n",
        "class Controller():\n",
        "  \n",
        "    def __init__(self, lstmUnits=100, minibatchSize=8, lr=1e-2,\n",
        "                nSubpolicies=5, nOpsPerSubpolicy=2,\n",
        "                transforms=[], nProbabilities=6, nMagnitudes=5):\n",
        "\n",
        "      \"\"\"\n",
        "      Controller object which generates transformation policies,\n",
        "      sets of subpolicies each of which contain transform operations\n",
        "      \n",
        "      Consists of a neural net which takes a constant \"dummy\" input state\n",
        "      Feeds through a LSTM, then a set of parallel dense layers with\n",
        "      softmax activation.  Each dense layer corresponds with a decision\n",
        "      in selecting the policy: A transform type, probability, and magnitude\n",
        "      for each Operation\n",
        "      \n",
        "      Args:\n",
        "      \n",
        "      lstmUnits: The output dimension of the LSTM encoder\n",
        "      \n",
        "      minibatchSize: How many times to sample policies and train a child model\n",
        "                     before fitting based on those sample policy/accuracy\n",
        "                     pairs\n",
        "      lr: Learning rate for the controller net\n",
        "      \n",
        "      nSubpolicies:  The number of different subpolicies to generate\n",
        "      \n",
        "      nOpsPerSubpolicy: The number of operations in each subpolicy\n",
        "      \n",
        "      transforms: a list tuples identifying the possible image transformations\n",
        "                  each representing (function, minMagnitude, maxMagnitude)\n",
        "\n",
        "      nProbabilities: How many evenly-spaced discrete probability values will \n",
        "                      be considered: 11 means that each operation will have a \n",
        "                      0%, 10%, 20% ... 80%, 90%, or 100% of being applied.\n",
        "                      \n",
        "      nMagnitudes: How many evenly-spaced discrete magnitude values will be\n",
        "                   considered for each operation. This will mean different\n",
        "                   things to different operations\n",
        "                   \n",
        "      \"\"\"\n",
        "      self.lstmUnits = 100\n",
        "      self.minibatchSize = minibatchSize\n",
        "      self.lr = lr\n",
        "      self.nSubpolicies = nSubpolicies\n",
        "      self.nOpsPerSubpolicy = nOpsPerSubpolicy\n",
        "      self.transforms = transforms\n",
        "      self.nTransforms = len(transforms)\n",
        "      self.nProbabilities = nProbabilities\n",
        "      self.nMagnitudes = nMagnitudes\n",
        "      self.softmaxCache = None\n",
        "      self.buildModel()\n",
        "      \n",
        "    def buildModel(self):\n",
        "\n",
        "      \"\"\"\n",
        "      Builds the neural net to generate policy probabilities.\n",
        "      \n",
        "      Each forward pass produces 3 softmax for each operation:\n",
        "      Operation Type, Probability, Magnitude.\n",
        "      Each subpolicy has self.nOpsPerSubpolicy such Operations, and each\n",
        "      policy has self.nSubpolicies such subpolicies.\n",
        "\n",
        "      To set the loss we want to minimize, we need the following placeholders,\n",
        "      which are given in feedDict each training step:\n",
        "        selectionMask_ph: Binary mask for each softmax layer indicating which \n",
        "          operation type, probability, and magnitude was selected for each\n",
        "          Operation in each Subpolicy. \n",
        "          All concatenated together to match the shape of the concatSoftmaxes\n",
        "\n",
        "        score_ph: Single score for each sample\n",
        "\n",
        "      Each training step, we apply the selectionMask_ph to the concatSoftmaxes,\n",
        "      so backprop will only update the weights leading to the subpolicy choices\n",
        "      made in this particular step.  These are multiplied by the \n",
        "      score we pass, and we create an optimizer to maximize the mean of this\n",
        "      tensor. (well, minimize for negative score)\n",
        "\n",
        "      If the model did well, we pass a positive accuracy score along with the\n",
        "      selectionMask.  The optimizer will update our weights which would lead\n",
        "      to the softmax selections we saw.\n",
        "      \"\"\"\n",
        "      self.input_ph = tf.placeholder(shape=(None, 1,1),\n",
        "                                     dtype=tf.float32,\n",
        "                                     name='inputLayer')\n",
        "\n",
        "      self.lstmLayerOutput = tf.keras.layers.CuDNNLSTM(\n",
        "                            units=self.lstmUnits,\n",
        "                            return_sequences=True,\n",
        "                            name='controller')(self.input_ph)\n",
        "\n",
        "      self.softmaxes = []\n",
        "\n",
        "      for j in range(self.nSubpolicies):\n",
        "        for i in range(self.nOpsPerSubpolicy):\n",
        "            name = 'pol%d-op%d-' % (j+1, i+1)\n",
        "\n",
        "            for units, n in [[self.nTransforms, 't'],\n",
        "                             [self.nProbabilities, 'p'],\n",
        "                             [self.nMagnitudes, 'm']]:\n",
        "              self.softmaxOutputs.append(layers.Dense(units,\n",
        "                                        activation='softmax',\n",
        "                                        name=name + n)(self.lstmLayerOutput))\n",
        "\n",
        "      concatSoftmaxes = tf.concat(self.softmaxOutputs, axis=2, name='concatSoftmaxes')\n",
        "      self.score_ph = tf.placeholder(shape=(), dtype=tf.float32)\n",
        "\n",
        "      maskSize = (self.nTransforms + self.nProbabilities + self.nMagnitudes)\n",
        "      maskSize *= self.nSubpolicies\n",
        "      maskSize *= self.nOpsPerSubpolicy\n",
        "\n",
        "      self.selectionMask_ph = tf.placeholder(\n",
        "                           shape=(maskSize),\n",
        "                           dtype=tf.float32,\n",
        "                           name='selectionMask')\n",
        "\n",
        "      maskedSoftmaxes = self.selectionMask_ph * concatSoftmaxes\n",
        "      loss = -tf.reduce_mean(self.score_ph * maskedSoftmaxes)\n",
        "      self.optimizer = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(loss)      \n",
        "      \n",
        "    def fit(self, selectionMasks, scores):\n",
        "      \"\"\"\n",
        "      Fits the model based on a batch of data tuples, (mask, score)\n",
        "      indicating a policy selection and the accuracy of a child model\n",
        "      trained with that data augmentation policy.\n",
        "      \"\"\"\n",
        "      \n",
        "      meanScore = np.mean(scores)\n",
        "      \n",
        "      session = backend.get_session()\n",
        "      assert len(selectionMasks) >= self.minibatchSize\n",
        "      assert len(scores) >= self.minibatchSize\n",
        "      \n",
        "      for mask, score in zip(selectionMasks[-self.minibatchSize:],\n",
        "                             scores[-self.minibatchSize:]):\n",
        "        fd = {}\n",
        "        fd[self.selectionMask_ph] = mask\n",
        "        fd[self.score_ph] = score - meanScore\n",
        "        fd[self.input_ph] = np.zeros([1,1,1])\n",
        "      session.run(self.optimizer, feed_dict=fd)\n",
        "      self.softmaxCache = None\n",
        "      \n",
        "      return self\n",
        "    \n",
        "    def getSoftmaxes(self):\n",
        "      session = backend.get_session()\n",
        "      softmaxes = session.run(self.softmaxOutputs,\n",
        "                              feed_dict={self.input_ph:np.zeros([1,1,1])})\n",
        "      softmaxes = [np.squeeze(s) for s in softmaxes]\n",
        "      self.softmaxCache = softmaxes\n",
        "      \n",
        "      return softmaxes\n",
        "   \n",
        "    def getPolicy(self, softmaxes=None):\n",
        "      \"\"\"\n",
        "      Generates a policy and the corresponding selectionMask      \n",
        "      based on the passed softmaxes or the softmaxes from the previous\n",
        "      time the model was used to create softmaxes\n",
        "      \n",
        "      Args:\n",
        "        softmaxes: a list of one-dimensional np.arrays, each 3 corresponding to\n",
        "          [probabilities of selecting each transformFunction type],\n",
        "          [probabilities of selecting each probability],\n",
        "          [probabilities of selecting each magnitute],\n",
        "          ...\n",
        "      \n",
        "      Returns:\n",
        "        policy: is a list of Subpolicies, each with Operations, selected based\n",
        "          on the probabilities passed in softmaxes\n",
        "        selectionMask is a single-dimension binary array, indicating\n",
        "          which of the options was selected\n",
        "\n",
        "      \n",
        "      \"\"\"\n",
        "      if softmaxes is None:\n",
        "        if self.softmaxCache is None:\n",
        "          softmaxes = self.getSoftmaxes()\n",
        "        else:\n",
        "          softmaxes = self.softmaxCache\n",
        "        \n",
        "      typeIdentity = np.eye(self.nTransforms)\n",
        "      probIdentity = np.eye(self.nProbabilities)\n",
        "      magIdentity = np.eye(self.nMagnitudes)\n",
        "\n",
        "      subpolicies = []\n",
        "      sRow = 0 #I find this easier to interpret\n",
        "      \n",
        "      policySelectionMask = []\n",
        "      for i in range(self.nSubpolicies):\n",
        "        operations = []\n",
        "        for j in range(self.nOpsPerSubpolicy):\n",
        "          typeSelection = np.random.choice(self.nTransforms, p=softmaxes[sRow])\n",
        "          probSelection = np.random.choice(self.nProbabilities, p=softmaxes[sRow+1])\n",
        "          magSelection = np.random.choice(self.nMagnitudes, p=softmaxes[sRow+2])\n",
        "          \n",
        "          policySelectionMask.extend(typeIdentity[typeSelection])\n",
        "          policySelectionMask.extend(probIdentity[probSelection])          \n",
        "          policySelectionMask.extend(magIdentity[magSelection])\n",
        "          \n",
        "          transform = self.transforms[typeSelection]\n",
        "          \n",
        "          probability = np.linspace(0, 1, self.nProbabilities)[probSelection]\n",
        "          magnitude = np.linspace(transform[1],\n",
        "                                  transform[2],\n",
        "                                  self.nMagnitudes)[magSelection]\n",
        "          operations.append(Operation(transform[0], probability, magnitude))\n",
        "          sRow += 3\n",
        "        subpolicies.append(Subpolicy(operations))\n",
        "      return subpolicies, policySelectionMask\n",
        "\n",
        "    def interpretMask(self, mask):\n",
        "      \"\"\"\n",
        "      Takes a selectionMask and returns the policy it indicates.\n",
        "      This is useful if we want to take the selections which scored well\n",
        "      and make the corresponding policies/subpolicies\n",
        "      \"\"\"\n",
        "      maskPosition = 0\n",
        "      fauxSoftmaxes = []\n",
        "\n",
        "      for i in range(self.nSubpolicies):\n",
        "        for j in range(self.nOpsPerSubpolicy):\n",
        "          fauxSoftmaxes.append(mask[maskPosition: maskPosition+self.nTransforms])\n",
        "          maskPosition += self.nTransforms\n",
        "\n",
        "          fauxSoftmaxes.append(mask[maskPosition: maskPosition+self.nProbabilities])\n",
        "          maskPosition += self.nProbabilities\n",
        "\n",
        "          fauxSoftmaxes.append(mask[maskPosition: maskPosition+self.nMagnitudes])\n",
        "          maskPosition += self.nMagnitudes\n",
        "      return self.getPolicy(fauxSoftmaxes)[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tnjd1kvi1fLw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def augmentGenerator(policy, X, y, batch):\n",
        "  while True:\n",
        "    ix = np.arange(len(X))\n",
        "    np.random.shuffle(ix)\n",
        "    for i in range(len(X) // batch):\n",
        "      batchIndexes = ix[i*batch:(i+1)*batch]\n",
        "      batchX = X[batchIndexes]\n",
        "      batchy = y[batchIndexes]\n",
        "      subpolicy = np.random.choice(policy)\n",
        "      transformedX = subpolicy(batchX)\n",
        "      transformedX = transformedX.astype(np.float32) / 255\n",
        "      yield transformedX, batchy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Q4c3Z2CwknJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "81bb7599-3a28-46c0-edcf-ae1296bf198c"
      },
      "cell_type": "code",
      "source": [
        "from keras import datasets\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(XtrainFull, ytrainFull), (Xtest, ytest) = datasets.cifar10.load_data()\n",
        "ix = np.arange(len(XtrainFull))\n",
        "np.random.shuffle(ix)\n",
        "Xtrain = XtrainFull[ix[:500]]\n",
        "ytrain = ytrainFull[ix[:500]]\n",
        "ytrain = to_categorical(ytrain)\n",
        "ytest = to_categorical(ytest)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 42s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hsm5dcO9zk5x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "class Child():\n",
        "  def __init__(self, epochs=256, batchSize=64, inputShape=[32,32,3],\n",
        "              num_classes=10):\n",
        "    # architecture from: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
        "\n",
        "    self.epochs = epochs\n",
        "    self.batchSize = batchSize\n",
        "    self.inputShape = inputShape\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                     activation='relu', padding='same',\n",
        "                     input_shape=inputShape))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same',))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same',))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=categorical_crossentropy,\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    self.model = model\n",
        "\n",
        "  def fit(self, generator, nbatches):\n",
        "    self.model.fit_generator(generator,\n",
        "                             steps_per_epoch = nbatches,\n",
        "                             epochs=self.epochs,\n",
        "                             use_multiprocessing=True,\n",
        "                             verbose=0)\n",
        "    return self\n",
        "  \n",
        "  def evaluate(self, X, y):\n",
        "    return self.model.evaluate(X/255., y, verbose=0)[1]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AID6NK6Sehcb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "e6d692ff-c7a6-4f22-ea96-abe4d20d8e75"
      },
      "cell_type": "code",
      "source": [
        "Child().model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               2097280   \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 2,154,890\n",
            "Trainable params: 2,154,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ndGPyxTVzMj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3213
        },
        "outputId": "fefe13aa-3609-4bf6-c785-41189705d42e"
      },
      "cell_type": "code",
      "source": [
        "tic = time.time()\n",
        "print ('Preparing Controller')\n",
        "controller = Controller(transforms=transformations, minibatchSize=16, lr=3e-2,\n",
        "                       nSubpolicies=5)\n",
        "toc = time.time()\n",
        "print (\"Controller ready, took %ds\" % (toc-tic)) \n",
        "accuracies = []\n",
        "selectionMasks = []\n",
        "savedSoftmaxes = []\n",
        "\n",
        "for i in range(32):\n",
        "  print (\"Iteration %d\" % i)\n",
        "  softmaxes = controller.getSoftmaxes()\n",
        "  savedSoftmaxes.append(softmaxes)\n",
        "  \n",
        "  for policySample in range(controller.minibatchSize):\n",
        "    policy, selectionMask = controller.getPolicy(softmaxes)\n",
        "    \n",
        "    selectionMasks.append(selectionMask)\n",
        "    \n",
        "    child = Child()\n",
        "\n",
        "    tic = time.time()\n",
        "    aug = augmentGenerator(policy, Xtrain, ytrain, child.batchSize)\n",
        "    child.fit(aug, len(Xtrain) // child.batchSize)\n",
        "    toc = time.time()\n",
        "\n",
        "    accuracy = child.evaluate(Xtest, ytest)\n",
        "    print('-> Child accuracy: %.3f (elaspsed time: %ds)' % (accuracy, (toc-tic)))\n",
        "    accuracies.append(accuracy)\n",
        "    \n",
        "  controller.fit(selectionMasks, accuracies)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing Controller\n",
            "Controller ready, took 4s\n",
            "Iteration 0\n",
            "-> Child accuracy: 0.329 (elaspsed time: 64s)\n",
            "-> Child accuracy: 0.353 (elaspsed time: 50s)\n",
            "-> Child accuracy: 0.384 (elaspsed time: 50s)\n",
            "-> Child accuracy: 0.380 (elaspsed time: 52s)\n",
            "-> Child accuracy: 0.363 (elaspsed time: 55s)\n",
            "-> Child accuracy: 0.341 (elaspsed time: 52s)\n",
            "-> Child accuracy: 0.362 (elaspsed time: 52s)\n",
            "-> Child accuracy: 0.371 (elaspsed time: 52s)\n",
            "-> Child accuracy: 0.309 (elaspsed time: 52s)\n",
            "-> Child accuracy: 0.381 (elaspsed time: 53s)\n",
            "-> Child accuracy: 0.361 (elaspsed time: 58s)\n",
            "-> Child accuracy: 0.330 (elaspsed time: 63s)\n",
            "-> Child accuracy: 0.352 (elaspsed time: 65s)\n",
            "-> Child accuracy: 0.390 (elaspsed time: 65s)\n",
            "-> Child accuracy: 0.381 (elaspsed time: 52s)\n",
            "-> Child accuracy: 0.378 (elaspsed time: 59s)\n",
            "Iteration 1\n",
            "-> Child accuracy: 0.345 (elaspsed time: 53s)\n",
            "-> Child accuracy: 0.371 (elaspsed time: 54s)\n",
            "-> Child accuracy: 0.406 (elaspsed time: 55s)\n",
            "-> Child accuracy: 0.375 (elaspsed time: 67s)\n",
            "-> Child accuracy: 0.401 (elaspsed time: 53s)\n",
            "-> Child accuracy: 0.402 (elaspsed time: 54s)\n",
            "-> Child accuracy: 0.356 (elaspsed time: 55s)\n",
            "-> Child accuracy: 0.369 (elaspsed time: 58s)\n",
            "-> Child accuracy: 0.401 (elaspsed time: 54s)\n",
            "-> Child accuracy: 0.382 (elaspsed time: 57s)\n",
            "-> Child accuracy: 0.345 (elaspsed time: 61s)\n",
            "-> Child accuracy: 0.383 (elaspsed time: 65s)\n",
            "-> Child accuracy: 0.340 (elaspsed time: 62s)\n",
            "-> Child accuracy: 0.383 (elaspsed time: 64s)\n",
            "-> Child accuracy: 0.309 (elaspsed time: 64s)\n",
            "-> Child accuracy: 0.394 (elaspsed time: 55s)\n",
            "Iteration 2\n",
            "-> Child accuracy: 0.381 (elaspsed time: 56s)\n",
            "-> Child accuracy: 0.327 (elaspsed time: 69s)\n",
            "-> Child accuracy: 0.363 (elaspsed time: 72s)\n",
            "-> Child accuracy: 0.391 (elaspsed time: 68s)\n",
            "-> Child accuracy: 0.376 (elaspsed time: 58s)\n",
            "-> Child accuracy: 0.394 (elaspsed time: 57s)\n",
            "-> Child accuracy: 0.395 (elaspsed time: 63s)\n",
            "-> Child accuracy: 0.405 (elaspsed time: 60s)\n",
            "-> Child accuracy: 0.361 (elaspsed time: 67s)\n",
            "-> Child accuracy: 0.380 (elaspsed time: 67s)\n",
            "-> Child accuracy: 0.379 (elaspsed time: 59s)\n",
            "-> Child accuracy: 0.361 (elaspsed time: 58s)\n",
            "-> Child accuracy: 0.362 (elaspsed time: 63s)\n",
            "-> Child accuracy: 0.348 (elaspsed time: 59s)\n",
            "-> Child accuracy: 0.366 (elaspsed time: 58s)\n",
            "-> Child accuracy: 0.376 (elaspsed time: 58s)\n",
            "Iteration 3\n",
            "-> Child accuracy: 0.318 (elaspsed time: 59s)\n",
            "-> Child accuracy: 0.304 (elaspsed time: 60s)\n",
            "-> Child accuracy: 0.399 (elaspsed time: 59s)\n",
            "-> Child accuracy: 0.383 (elaspsed time: 60s)\n",
            "-> Child accuracy: 0.355 (elaspsed time: 59s)\n",
            "-> Child accuracy: 0.409 (elaspsed time: 60s)\n",
            "-> Child accuracy: 0.391 (elaspsed time: 74s)\n",
            "-> Child accuracy: 0.381 (elaspsed time: 67s)\n",
            "-> Child accuracy: 0.371 (elaspsed time: 65s)\n",
            "-> Child accuracy: 0.364 (elaspsed time: 60s)\n",
            "-> Child accuracy: 0.333 (elaspsed time: 58s)\n",
            "-> Child accuracy: 0.396 (elaspsed time: 61s)\n",
            "-> Child accuracy: 0.385 (elaspsed time: 63s)\n",
            "-> Child accuracy: 0.376 (elaspsed time: 62s)\n",
            "-> Child accuracy: 0.403 (elaspsed time: 65s)\n",
            "-> Child accuracy: 0.341 (elaspsed time: 63s)\n",
            "Iteration 4\n",
            "-> Child accuracy: 0.335 (elaspsed time: 80s)\n",
            "-> Child accuracy: 0.391 (elaspsed time: 62s)\n",
            "-> Child accuracy: 0.374 (elaspsed time: 72s)\n",
            "-> Child accuracy: 0.379 (elaspsed time: 69s)\n",
            "-> Child accuracy: 0.354 (elaspsed time: 68s)\n",
            "-> Child accuracy: 0.360 (elaspsed time: 62s)\n",
            "-> Child accuracy: 0.370 (elaspsed time: 64s)\n",
            "-> Child accuracy: 0.417 (elaspsed time: 65s)\n",
            "-> Child accuracy: 0.368 (elaspsed time: 64s)\n",
            "-> Child accuracy: 0.349 (elaspsed time: 66s)\n",
            "-> Child accuracy: 0.389 (elaspsed time: 66s)\n",
            "-> Child accuracy: 0.374 (elaspsed time: 65s)\n",
            "-> Child accuracy: 0.345 (elaspsed time: 68s)\n",
            "-> Child accuracy: 0.349 (elaspsed time: 69s)\n",
            "-> Child accuracy: 0.378 (elaspsed time: 72s)\n",
            "-> Child accuracy: 0.393 (elaspsed time: 79s)\n",
            "Iteration 5\n",
            "-> Child accuracy: 0.399 (elaspsed time: 66s)\n",
            "-> Child accuracy: 0.335 (elaspsed time: 65s)\n",
            "-> Child accuracy: 0.347 (elaspsed time: 70s)\n",
            "-> Child accuracy: 0.363 (elaspsed time: 66s)\n",
            "-> Child accuracy: 0.373 (elaspsed time: 67s)\n",
            "-> Child accuracy: 0.358 (elaspsed time: 68s)\n",
            "-> Child accuracy: 0.351 (elaspsed time: 67s)\n",
            "-> Child accuracy: 0.396 (elaspsed time: 70s)\n",
            "-> Child accuracy: 0.357 (elaspsed time: 76s)\n",
            "-> Child accuracy: 0.373 (elaspsed time: 76s)\n",
            "-> Child accuracy: 0.381 (elaspsed time: 68s)\n",
            "-> Child accuracy: 0.410 (elaspsed time: 68s)\n",
            "-> Child accuracy: 0.393 (elaspsed time: 68s)\n",
            "-> Child accuracy: 0.329 (elaspsed time: 68s)\n",
            "-> Child accuracy: 0.328 (elaspsed time: 70s)\n",
            "-> Child accuracy: 0.320 (elaspsed time: 74s)\n",
            "Iteration 6\n",
            "-> Child accuracy: 0.412 (elaspsed time: 70s)\n",
            "-> Child accuracy: 0.340 (elaspsed time: 70s)\n",
            "-> Child accuracy: 0.382 (elaspsed time: 72s)\n",
            "-> Child accuracy: 0.408 (elaspsed time: 78s)\n",
            "-> Child accuracy: 0.358 (elaspsed time: 70s)\n",
            "-> Child accuracy: 0.366 (elaspsed time: 71s)\n",
            "-> Child accuracy: 0.379 (elaspsed time: 72s)\n",
            "-> Child accuracy: 0.366 (elaspsed time: 72s)\n",
            "-> Child accuracy: 0.367 (elaspsed time: 70s)\n",
            "-> Child accuracy: 0.347 (elaspsed time: 77s)\n",
            "-> Child accuracy: 0.380 (elaspsed time: 73s)\n",
            "-> Child accuracy: 0.342 (elaspsed time: 71s)\n",
            "-> Child accuracy: 0.394 (elaspsed time: 71s)\n",
            "-> Child accuracy: 0.384 (elaspsed time: 72s)\n",
            "-> Child accuracy: 0.363 (elaspsed time: 72s)\n",
            "-> Child accuracy: 0.358 (elaspsed time: 71s)\n",
            "Iteration 7\n",
            "-> Child accuracy: 0.353 (elaspsed time: 74s)\n",
            "-> Child accuracy: 0.371 (elaspsed time: 73s)\n",
            "-> Child accuracy: 0.356 (elaspsed time: 76s)\n",
            "-> Child accuracy: 0.393 (elaspsed time: 73s)\n",
            "-> Child accuracy: 0.346 (elaspsed time: 86s)\n",
            "-> Child accuracy: 0.400 (elaspsed time: 75s)\n",
            "-> Child accuracy: 0.388 (elaspsed time: 75s)\n",
            "-> Child accuracy: 0.417 (elaspsed time: 73s)\n",
            "-> Child accuracy: 0.376 (elaspsed time: 76s)\n",
            "-> Child accuracy: 0.371 (elaspsed time: 77s)\n",
            "-> Child accuracy: 0.364 (elaspsed time: 80s)\n",
            "-> Child accuracy: 0.384 (elaspsed time: 75s)\n",
            "-> Child accuracy: 0.398 (elaspsed time: 75s)\n",
            "-> Child accuracy: 0.372 (elaspsed time: 78s)\n",
            "-> Child accuracy: 0.345 (elaspsed time: 80s)\n",
            "-> Child accuracy: 0.350 (elaspsed time: 79s)\n",
            "Iteration 8\n",
            "-> Child accuracy: 0.413 (elaspsed time: 76s)\n",
            "-> Child accuracy: 0.344 (elaspsed time: 86s)\n",
            "-> Child accuracy: 0.386 (elaspsed time: 77s)\n",
            "-> Child accuracy: 0.378 (elaspsed time: 80s)\n",
            "-> Child accuracy: 0.401 (elaspsed time: 78s)\n",
            "-> Child accuracy: 0.367 (elaspsed time: 81s)\n",
            "-> Child accuracy: 0.373 (elaspsed time: 84s)\n",
            "-> Child accuracy: 0.328 (elaspsed time: 80s)\n",
            "-> Child accuracy: 0.361 (elaspsed time: 81s)\n",
            "-> Child accuracy: 0.354 (elaspsed time: 79s)\n",
            "-> Child accuracy: 0.355 (elaspsed time: 79s)\n",
            "-> Child accuracy: 0.358 (elaspsed time: 80s)\n",
            "-> Child accuracy: 0.385 (elaspsed time: 84s)\n",
            "-> Child accuracy: 0.373 (elaspsed time: 85s)\n",
            "-> Child accuracy: 0.336 (elaspsed time: 80s)\n",
            "-> Child accuracy: 0.378 (elaspsed time: 81s)\n",
            "Iteration 9\n",
            "-> Child accuracy: 0.396 (elaspsed time: 80s)\n",
            "-> Child accuracy: 0.344 (elaspsed time: 82s)\n",
            "-> Child accuracy: 0.386 (elaspsed time: 81s)\n",
            "-> Child accuracy: 0.344 (elaspsed time: 84s)\n",
            "-> Child accuracy: 0.355 (elaspsed time: 83s)\n",
            "-> Child accuracy: 0.389 (elaspsed time: 83s)\n",
            "-> Child accuracy: 0.379 (elaspsed time: 83s)\n",
            "-> Child accuracy: 0.346 (elaspsed time: 84s)\n",
            "-> Child accuracy: 0.338 (elaspsed time: 84s)\n",
            "-> Child accuracy: 0.332 (elaspsed time: 85s)\n",
            "-> Child accuracy: 0.340 (elaspsed time: 83s)\n",
            "-> Child accuracy: 0.347 (elaspsed time: 82s)\n",
            "-> Child accuracy: 0.363 (elaspsed time: 85s)\n",
            "-> Child accuracy: 0.353 (elaspsed time: 81s)\n",
            "-> Child accuracy: 0.388 (elaspsed time: 85s)\n",
            "-> Child accuracy: 0.410 (elaspsed time: 82s)\n",
            "Iteration 10\n",
            "-> Child accuracy: 0.351 (elaspsed time: 86s)\n",
            "-> Child accuracy: 0.308 (elaspsed time: 89s)\n",
            "-> Child accuracy: 0.377 (elaspsed time: 86s)\n",
            "-> Child accuracy: 0.401 (elaspsed time: 87s)\n",
            "-> Child accuracy: 0.366 (elaspsed time: 88s)\n",
            "-> Child accuracy: 0.404 (elaspsed time: 85s)\n",
            "-> Child accuracy: 0.394 (elaspsed time: 84s)\n",
            "-> Child accuracy: 0.349 (elaspsed time: 87s)\n",
            "-> Child accuracy: 0.374 (elaspsed time: 84s)\n",
            "-> Child accuracy: 0.368 (elaspsed time: 87s)\n",
            "-> Child accuracy: 0.371 (elaspsed time: 86s)\n",
            "-> Child accuracy: 0.352 (elaspsed time: 91s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MiRfCHeHlKOH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f-bShmmIohPh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}