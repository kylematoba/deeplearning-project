{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_wide_res_net_matoba.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kylematoba/deeplearning-project/blob/master/keras_wide_res_net_matoba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fr2z4dXiyJfj",
        "colab_type": "code",
        "outputId": "66cd699f-64dd-442a-f124-10854e3421a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "# A heavily modified version of https://github.com/tail-island/try-wide-residual-net\n",
        "!pip3 install funcy\n",
        "# !pip3 install tqdm\n",
        "# !pip3 install tensorboard\n",
        "# !pip3 install npm\n",
        "# !pip3 install tensorboardcolab\n",
        "\n",
        "# !pip3 install pydot\n",
        "# !pip3 install pydot_ng\n",
        "# !pip3 install pydotplus\n",
        "# !pip3 install graphviz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting funcy\n",
            "  Downloading https://files.pythonhosted.org/packages/47/a4/204fa23012e913839c2da4514b92f17da82bf5fc8c2c3d902fa3fa3c6eec/funcy-1.11-py2.py3-none-any.whl\n",
            "Installing collected packages: funcy\n",
            "Successfully installed funcy-1.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "q2xKxjcmIIx5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls\n",
        "# from tensorboardcolab import *\n",
        "# tbc = TensorBoardColab()\n",
        "# tbc = TensorBoardColab(startup_waiting_time=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_MvMJmyKEekN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import pickle\n",
        "import copy\n",
        "import functools\n",
        "import logging\n",
        "\n",
        "from typing import Any, Callable, List, Tuple, Union\n",
        "from operator import getitem, attrgetter\n",
        "from collections import namedtuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import ImageOps\n",
        "from PIL import ImageEnhance\n",
        "from PIL import ImageFilter\n",
        "from PIL import Image\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.layers import Activation, Add, BatchNormalization, Conv2D, Dense, GlobalAveragePooling2D, Input, Layer\n",
        "from tensorflow.keras.models import Model, save_model, load_model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# from tqdm import tqdm\n",
        "from funcy import concat, identity, juxt, partial, rcompose, repeat, repeatedly, take\n",
        "\n",
        "# from google.colab import drive\n",
        "# import google.colab\n",
        "# import google.appengine\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hnbyYOOQH4po",
        "colab_type": "code",
        "outputId": "24da7f4c-246e-4893-d959-398d00642d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "FORMAT = \"%(asctime)s %(process)s %(thread)s: %(message)s\"\n",
        "logging.basicConfig(level=logging.DEBUG, format=FORMAT, stream=sys.stdout)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "environ_dict = dict(os.environ)\n",
        "use_tpu = 'COLAB_TPU_ADDR' in environ_dict.keys()\n",
        "\n",
        "logger.info(sys.version)\n",
        "logger.info(\"{}\".format(\"Running in ipython\" if 'ipykernel' in sys.modules else \"\"))\n",
        "logger.info(\"Numpy version {}\".format(np.__version__))\n",
        "logger.info(\"TensorFlow version {}\".format(tf.__version__))\n",
        "# logger.info(\"Keras version {}\".format(keras.__version__))\n",
        "if use_tpu:\n",
        "    logger.info(\"Running on TPU\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-04 13:23:07,227 74 139790496442240: 3.6.7 (default, Oct 22 2018, 11:32:17) \n",
            "[GCC 8.2.0]\n",
            "2018-12-04 13:23:07,229 74 139790496442240: Running in ipython\n",
            "2018-12-04 13:23:07,230 74 139790496442240: Numpy version 1.14.6\n",
            "2018-12-04 13:23:07,231 74 139790496442240: TensorFlow version 1.12.0\n",
            "2018-12-04 13:23:07,232 74 139790496442240: Running on TPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V6DGhtaGbv5n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lzcguFhGyByy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def download_data() -> None:\n",
        "    url = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
        "    shutil.copytree(tf.keras.utils.get_file('cifar-10-batches-py', origin=url, untar=True), './data')\n",
        "\n",
        "    \n",
        "def load_batch(batch_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    with open(batch_path, 'rb') as f:\n",
        "        batch = pickle.load(f, encoding='bytes')\n",
        "    data_np = np.array(batch[b'data'])\n",
        "    labels_np = np.array(batch[b'labels'])\n",
        "    batch_data = data_np.reshape(data_np.shape[0], 3, 32, 32).transpose(0, 2, 3, 1) / 255\n",
        "    batch_labels = tf.keras.utils.to_categorical(labels_np)\n",
        "    return (batch_data, batch_labels)\n",
        "\n",
        "\n",
        "def load_batches(paths: List[str]):\n",
        "    return tuple(map(np.concatenate, zip(*map(load_batch, paths))))\n",
        "\n",
        "\n",
        "def load_data(data_path='./data') -> Tuple[np.ndarray, np.ndarray]:\n",
        "    if not os.path.exists('./data'):\n",
        "        download_data()\n",
        "    paths = sorted(map(attrgetter('path'), filter(lambda directory_entry: directory_entry.name.startswith('data_batch_'), os.scandir(data_path))))\n",
        "    xy_train = load_batches(paths)\n",
        "    xy_validation = load_batch('{0}/test_batch'.format(data_path))\n",
        "    return (xy_train, xy_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwfLMkmHx2iO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def computational_graph(class_size):\n",
        "    def ljuxt(*fs):\n",
        "        return rcompose(juxt(*fs), list)\n",
        "\n",
        "    def batch_normalization():\n",
        "        return BatchNormalization()\n",
        "\n",
        "    def relu() -> tf.keras.layers.Activation:\n",
        "        return Activation('relu')\n",
        "\n",
        "    def conv(filter_size: int, kernel_size: int, stride_size: int=1) -> Layer:\n",
        "        return Conv2D(filter_size, kernel_size, strides=stride_size, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), use_bias=False)\n",
        "\n",
        "    def add():\n",
        "        return Add()\n",
        "\n",
        "    def global_average_pooling():\n",
        "        return GlobalAveragePooling2D()\n",
        "\n",
        "    def dense(units: int, activation: str) -> Layer:\n",
        "        return Dense(units, activation=activation, kernel_regularizer=l2(0.0005))\n",
        "\n",
        "    # Define WRN-28-10.\n",
        "    def first_residual_unit(filter_size: int, stride_size: int):\n",
        "        return rcompose(batch_normalization(),\n",
        "                        relu(),\n",
        "                        ljuxt(rcompose(conv(filter_size, 3, stride_size),\n",
        "                                       batch_normalization(),\n",
        "                                       relu(),\n",
        "                                       conv(filter_size, 3, 1)),\n",
        "                              rcompose(conv(filter_size, 1, stride_size))),\n",
        "                        add())\n",
        "\n",
        "    def residual_unit(filter_size):\n",
        "        return rcompose(ljuxt(rcompose(batch_normalization(),\n",
        "                                       relu(),\n",
        "                                       conv(filter_size, 3),\n",
        "                                       batch_normalization(),\n",
        "                                       relu(),\n",
        "                                       conv(filter_size, 3)),\n",
        "                              identity),\n",
        "                        add())\n",
        "\n",
        "    def residual_block(filter_size, stride_size, unit_size):\n",
        "        return rcompose(first_residual_unit(filter_size, stride_size),\n",
        "                        rcompose(*repeatedly(partial(residual_unit, filter_size), unit_size - 1)))\n",
        "\n",
        "    k = 10\n",
        "    n =  4\n",
        "    return rcompose(conv(16, 3),\n",
        "                    residual_block(16 * k, 1, n),\n",
        "                    residual_block(32 * k, 2, n),\n",
        "                    residual_block(64 * k, 2, n),\n",
        "                    batch_normalization(),\n",
        "                    relu(),\n",
        "                    global_average_pooling(),\n",
        "                    dense(class_size, 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aAKWy_dh1qf5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7355c424-3026-4854-f905-6b3fd9c5bee4"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "(x_train, y_train), (x_validation, y_validation) = load_data()\n",
        "# print(x_train.shape)\n",
        "# print(x_validation.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 29s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HVHi7FwKhYts",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Represents a Folder or File in your Google Drive\n",
        "GDriveItem = namedtuple('GDriveItem', ['name', 'fid'])\n",
        "\n",
        "# Represents Epoch information as returned from keras\n",
        "EpochData = namedtuple('EpochData', ['epoch', 'losses'])\n",
        "\n",
        "\n",
        "class GDriveSync:\n",
        "    \"\"\"\n",
        "    Simple up/downloading functionality to move local files into the cloud and vice versa.\n",
        "    Provides progress bars for both up- and download.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        auth.authenticate_user()  # prompt the user to access his Google Drive via the API\n",
        "        self.drive_service = build('drive', 'v3')\n",
        "        self.default_folder = self.find_items('Colab Notebooks')[0]\n",
        "\n",
        "    def find_items(self, name: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Find folders or files based on their name. This always searches the full Google Drive tree!\n",
        "        :param name: Term to be searched. All files containing this search term are returned.\n",
        "        \"\"\"\n",
        "        folder_list = self.drive_service.files().list(q='name contains \"%s\"' % name).execute()\n",
        "        folders = []\n",
        "        for folder in folder_list['files']:\n",
        "            folders.append(GDriveItem(folder['name'], folder['id']))\n",
        "        return folders\n",
        "\n",
        "    def upload_file_to_folder(self, local_file: str, folder=None) -> None:\n",
        "        \"\"\"\n",
        "        Upload a local file, optionally to a specific folder in Google Drive\n",
        "        :param local_file: Path to the local file\n",
        "        :param folder: (Option) GDriveItem which should be the parent.\n",
        "        \"\"\"\n",
        "        if folder is not None:\n",
        "            assert type(folder) == GDriveItem\t\n",
        "\n",
        "        file_metadata = {\n",
        "            'title': local_file,\n",
        "            'name': local_file\n",
        "        }\n",
        "\n",
        "        if folder is not None:\n",
        "            file_metadata['parents'] = [folder.fid]\n",
        "\n",
        "        media = MediaFileUpload(local_file, resumable=True)\n",
        "        created = self.drive_service.files().create(body=file_metadata,\n",
        "                                                    media_body=media,\n",
        "                                                    fields='id')\n",
        "        if folder is not None:\n",
        "            d = 'Uploading file %s to folder %s' % (local_file, folder.name)\n",
        "        else:\n",
        "            d = 'Uploading file %s' % local_file\n",
        "\n",
        "        response = None\n",
        "        while response is None:\n",
        "            status, response = created.next_chunk()\n",
        "                \n",
        "    def download_file_to_folder(self, \n",
        "                                remote_file: GDriveItem, \n",
        "                                path: str) -> None:\n",
        "        assert type(remote_file) == GDriveItem\n",
        "        request = self.drive_service.files().get_media(fileId=remote_file.fid)\n",
        "\n",
        "        with open(path, 'wb') as fh:\n",
        "            downloader = MediaIoBaseDownload(fh, request)\n",
        "            done = False\n",
        "            while done is False:\n",
        "                status, done = downloader.next_chunk()\n",
        "\n",
        "    def delete_file(self, file: GDriveItem) -> None:\n",
        "        assert type(file) == GDriveItem\n",
        "        request = self.drive_service.files().delete(fileId=file.fid)\n",
        "        request.execute()\n",
        "\n",
        "\n",
        "class GDriveCheckpointer(tf.keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Keras Callback that automatically saves models into your Google Drive.\n",
        "    Outdated checkpoints are automatically deleted remotely to prevent GDrive from filling up.\n",
        "    Checkpointing is controlled by two functions:\n",
        "        compare_fn(best_epoch: EpochData, current_epoch: EpochData) -> bool\n",
        "        - If this function returns true, the current_epoch is assumed to have better performance than the older best_epoch.\n",
        "        - e.g. return best_epoch.losses['val_acc'] < current_epoch.losses['val_acc']\n",
        "        filepath_fn(epoch: EpochData) -> Union[String, None]\n",
        "        - If this function returns None, the checkpoint is skipped. This can be used to skip backing up early epochs.\n",
        "          If it returns a String path, the model is uploaded into the default GDrive folder with the given file name.\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "                 compare_fn: Callable, \n",
        "                 filepath_fn: Callable, \n",
        "                 save_optimizer=False):\n",
        "        assert compare_fn is not None, 'Need a compare function which gets all the losses and evaluation data of two epochs and which needs to return True if the second one is better.'\n",
        "        assert filepath_fn is not None, 'Need a function that derives a file path based on a dictionary of losses and metrics.'\n",
        "\n",
        "        restart_from_backup = False\n",
        "        super(GDriveCheckpointer, self).__init__()\n",
        "        self.saver = GDriveSync()\n",
        "        self.compare_fn = compare_fn\n",
        "        self.filepath_fn = filepath_fn\n",
        "        self.best_epoch = None\n",
        "        self.best_filename = None\n",
        "        self.save_optimizer = save_optimizer\n",
        "\n",
        "    def on_epoch_end(self, epoch: int, logs={}):\n",
        "        losses = dict(logs)\n",
        "        epoch_data = EpochData(epoch, losses)\n",
        "        if self.best_epoch is None or self.compare_fn(self.best_epoch, epoch_data):\n",
        "            self.best_epoch = copy.deepcopy(epoch_data)\n",
        "            fn = self.filepath_fn(epoch_data)\n",
        "            if fn is not None and fn:\n",
        "                if self.best_filename:\n",
        "                    os.remove(self.best_filename)\n",
        "                    all_found = self.saver.find_items(self.best_filename)\n",
        "                    old_file = all_found[0]\n",
        "                    print('Removing old cloud file %s' % old_file.name)\n",
        "                    self.saver.delete_file(old_file)\n",
        "                self.best_filename = fn\n",
        "                self._save_checkpoint()\n",
        "            else:\n",
        "                print('Skipping upload because path function returned no path.')\n",
        "        else:\n",
        "            pass\n",
        "            # print('No improvement.')\n",
        "\n",
        "    def _save_checkpoint(self):\n",
        "        print('Saving {}'.format(self.best_filename))\n",
        "        # self.model.save(self.best_filename, include_optimizer=self.save_optimizer)\n",
        "        self.model.save(self.best_filename)\n",
        "        print('Uploading to {}'.format(self.saver.default_folder))\n",
        "        self.saver.upload_file_to_folder(self.best_filename, self.saver.default_folder)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hfTNTdhRng3r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def filepath_fn_unbound(filebase: str, \n",
        "                        x: EpochData) -> Union[str, None]:\n",
        "    # return 'VGG16_%s.h5' % new.losses['val_acc']\n",
        "    # filepath = str(epoch)\n",
        "    filepath = '{}_{:04d}'.format(filebase, x.epoch)\n",
        "    return filepath\n",
        "  \n",
        "\n",
        "def compare_fn(best_epoch: EpochData, \n",
        "               current_epoch: EpochData) -> bool:\n",
        "    save_every = 10\n",
        "    save = 0 == current_epoch.epoch % save_every\n",
        "    return save\n",
        "  \n",
        "  \n",
        "# filebase = 'wide_res_net'\n",
        "filebase = 'wide_res_net_cutout'\n",
        "filepath_fn = lambda x: filepath_fn_unbound(filebase, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wLizRtbkgRVL",
        "colab_type": "code",
        "outputId": "0ca94ab9-c28a-4f72-a675-ac72afd118d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "cell_type": "code",
      "source": [
        "# this one prompts for authorisation\n",
        "gdcp = GDriveCheckpointer(compare_fn, filepath_fn)\n",
        "# gdcp"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-04 13:24:01,670 74 139790496442240: Making request: POST https://accounts.google.com/o/oauth2/token\n",
            "2018-12-04 13:24:01,677 74 139790496442240: Starting new HTTPS connection (1): accounts.google.com\n",
            "2018-12-04 13:24:01,728 74 139790496442240: https://accounts.google.com:443 \"POST /o/oauth2/token HTTP/1.1\" 200 None\n",
            "2018-12-04 13:24:01,741 74 139790496442240: file_cache is unavailable when using oauth2client >= 4.0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    'file_cache is unavailable when using oauth2client >= 4.0.0')\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0\n",
            "2018-12-04 13:24:01,744 74 139790496442240: URL being requested: GET https://www.googleapis.com/discovery/v1/apis/drive/v3/rest\n",
            "2018-12-04 13:24:01,774 74 139790496442240: No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
            "2018-12-04 13:24:01,786 74 139790496442240: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22Colab+Notebooks%22&alt=json\n",
            "2018-12-04 13:24:01,787 74 139790496442240: Making request: POST https://accounts.google.com/o/oauth2/token\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NcH_ki4r-NBa",
        "colab_type": "code",
        "outputId": "0d951fbd-7299-48db-c580-a80a65e51514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "def get_last_filename(filebase: str) -> str:\n",
        "    remote_files = gdcp.saver.find_items(filebase)\n",
        "    sorted_filenames = sorted([x.name for x in remote_files])\n",
        "    if len(sorted_filenames) > 0:\n",
        "        last_filename = sorted_filenames[-1]\n",
        "    else:\n",
        "        last_filename = None\n",
        "    return last_filename\n",
        "\n",
        "attempt_reload_from_drive = True\n",
        "reload_from = '0290'\n",
        "last_filename = get_last_filename(filebase)\n",
        "\n",
        "if attempt_reload_from_drive and (last_filename is not None):\n",
        "    remote_files = gdcp.saver.find_items(last_filename)\n",
        "    remote_file = remote_files[0]\n",
        "    local_best_model_fn = remote_file.name\n",
        "    logger.info(\"Loading from {}\".format(local_best_model_fn))\n",
        "    gdcp.saver.download_file_to_folder(remote_file, local_best_model_fn)\n",
        "    model = load_model(local_best_model_fn)\n",
        "    initial_epoch = int(remote_file.name.split('_')[-1])\n",
        "else:\n",
        "    xshape = x_train.shape[1:]\n",
        "    yshape = y_train.shape[1]\n",
        "    model = Model(*juxt(identity, computational_graph(yshape))(Input(shape=xshape)))\n",
        "    optimizer = SGD(momentum=0.9)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])  # nesterov=True\n",
        "    initial_epoch = 0\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-04 13:24:02,137 74 139790496442240: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22wide_res_net_cutout%22&alt=json\n",
            "2018-12-04 13:24:03,249 74 139790496442240: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22wide_res_net_cutout_0090%22&alt=json\n",
            "2018-12-04 13:24:03,389 74 139790496442240: Loading from wide_res_net_cutout_0090\n",
            "2018-12-04 13:24:03,393 74 139790496442240: URL being requested: GET https://www.googleapis.com/drive/v3/files/1oAEB6Qynef4tHKcLuDhvC2Z8PD5dBUZd?alt=media\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dTu0zJCdCMG6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def create_cutout_mask(img_height, img_width, num_channels, size):\n",
        "    \"\"\"Creates a zero mask used for cutout of shape `img_height` x `img_width`.\n",
        "\n",
        "    Args:\n",
        "      img_height: Height of image cutout mask will be applied to.\n",
        "      img_width: Width of image cutout mask will be applied to.\n",
        "      num_channels: Number of channels in the image.\n",
        "      size: Size of the zeros mask.\n",
        "\n",
        "    Returns:\n",
        "      A mask of shape `img_height` x `img_width` with all ones except for a\n",
        "      square of zeros of shape `size` x `size`. This mask is meant to be\n",
        "      elementwise multiplied with the original image. Additionally returns\n",
        "      the `upper_coord` and `lower_coord` which specify where the cutout mask\n",
        "      will be applied.\n",
        "    \"\"\"\n",
        "    assert img_height == img_width\n",
        "\n",
        "    # Sample center where cutout mask will be applied\n",
        "    height_loc = np.random.randint(low=0, high=img_height)\n",
        "    width_loc = np.random.randint(low=0, high=img_width)\n",
        "\n",
        "    # Determine upper right and lower left corners of patch\n",
        "    upper_coord = (max(0, height_loc - size // 2), max(0, width_loc - size // 2))\n",
        "    lower_coord = (min(img_height, height_loc + size // 2),\n",
        "                   min(img_width, width_loc + size // 2))\n",
        "    mask_height = lower_coord[0] - upper_coord[0]\n",
        "    mask_width = lower_coord[1] - upper_coord[1]\n",
        "    assert mask_height > 0\n",
        "    assert mask_width > 0\n",
        "\n",
        "    mask = np.ones((img_height, img_width, num_channels))\n",
        "    zeros = np.zeros((mask_height, mask_width, num_channels))\n",
        "    mask[upper_coord[0]:lower_coord[0], upper_coord[1]:lower_coord[1], :] = (zeros)\n",
        "    return mask, upper_coord, lower_coord\n",
        "\n",
        "\n",
        "def cutout_numpy(img, size=16):\n",
        "    \"\"\"Apply cutout with mask of shape `size` x `size` to `img`.\n",
        "\n",
        "    The cutout operation is from the paper https://arxiv.org/abs/1708.04552.\n",
        "    This operation applies a `size`x`size` mask of zeros to a random location\n",
        "    within `img`.\n",
        "\n",
        "    Args:\n",
        "      img: Numpy image that cutout will be applied to.\n",
        "      size: Height/width of the cutout mask that will be\n",
        "\n",
        "    Returns:\n",
        "      A numpy tensor that is the result of applying the cutout mask to `img`.\n",
        "    \"\"\"\n",
        "    img_height, img_width, num_channels = (img.shape[0], img.shape[1],\n",
        "                                           img.shape[2])\n",
        "    assert len(img.shape) == 3\n",
        "    mask, _, _ = create_cutout_mask(img_height, img_width, num_channels, size)\n",
        "    return img * mask\n",
        "\n",
        "  \n",
        "def random_flip(x):\n",
        "    \"\"\"Flip the input x horizontally with 50% probability.\"\"\"\n",
        "    if np.random.rand(1)[0] > 0.5:\n",
        "        return np.fliplr(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def zero_pad_and_crop(img, amount=4):\n",
        "    \"\"\"Zero pad by `amount` zero pixels on each side then take a random crop.\n",
        "\n",
        "    Args:\n",
        "      img: numpy image that will be zero padded and cropped.\n",
        "      amount: amount of zeros to pad `img` with horizontally and verically.\n",
        "\n",
        "    Returns:\n",
        "      The cropped zero padded img. The returned numpy array will be of the same\n",
        "      shape as `img`.\n",
        "    \"\"\"\n",
        "    padded_img = np.zeros((img.shape[0] + amount * 2, img.shape[1] + amount * 2, img.shape[2]))\n",
        "    padded_img[amount:img.shape[0] + amount, amount:img.shape[1] + amount, :] = img\n",
        "    top = np.random.randint(low=0, high=2 * amount)\n",
        "    left = np.random.randint(low=0, high=2 * amount)\n",
        "    new_img = padded_img[top:top + img.shape[0], left:left + img.shape[1], :]\n",
        "    return new_img\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8dXO3DmuzsPH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def good_policies() -> List[tuple]:\n",
        "    \"\"\"AutoAugment policies found on analysis.\"\"\"\n",
        "    exp0_0 = [\n",
        "      [('flip_lr', 0.5, 5)],\n",
        "      [('TranslateY', 0.5, 5)],\n",
        "      [('TranslateX', 0.5, 5)],\n",
        "      [('ShearY', 0.5, 5)],\n",
        "      [('Solarize', 0.5, 5)],\n",
        "      [('Rotate', 0.5, 5)]\n",
        "    ]\n",
        "    return exp0_0\n",
        "\n",
        "gp = good_policies()\n",
        "gp\n",
        "# https://software.intel.com/en-us/articles/hands-on-ai-part-14-image-data-preprocessing-and-augmentation\n",
        "batch_size = 128\n",
        "checkpoint_period = 5\n",
        "\n",
        "#             epoch_policy = self.good_policies[np.random.choice(len(self.good_policies))]\n",
        "#             final_img = augmentation_transforms.apply_policy(epoch_policy, data)\n",
        "#             final_img = augmentation_transforms.random_flip(augmentation_transforms.zero_pad_and_crop(final_img, 4))\n",
        "#             final_img = augmentation_transforms.cutout_numpy(final_img)  # Apply cutout\n",
        "MEANS = [0.49139968, 0.48215841, 0.44653091]\n",
        "STDS = [0.24703223, 0.24348513, 0.26158784]\n",
        "\n",
        "def pil_wrap(img):\n",
        "    return Image.fromarray(np.uint8((img * STDS + MEANS) * 255.0)).convert('RGBA')\n",
        "\n",
        "\n",
        "def pil_unwrap(pil_img):\n",
        "    pic_array = (np.array(pil_img.getdata()).reshape((32, 32, 4)) / 255.0)\n",
        "    i1, i2 = np.where(pic_array[:, :, 3] == 0)\n",
        "    pic_array = (pic_array[:, :, :3] - MEANS) / STDS\n",
        "    pic_array[i1, i2] = [0, 0, 0]\n",
        "    return pic_array\n",
        "\n",
        "  \n",
        "def autoaugment(x: np.ndarray) -> np.ndarray:\n",
        "    x = pil_unwrap(pil_wrap(x).transpose(Image.FLIP_LEFT_RIGHT))  # [('flip_lr', 0.5, 5)],\n",
        "    return x\n",
        "  \n",
        "    \n",
        "if filebase == 'wide_res_net_cutout':\n",
        "    def preprocessing_function(x: np.ndarray) -> np.ndarray:\n",
        "        policy = lambda x: x\n",
        "        x = autoaugment(x)\n",
        "        x = random_flip(zero_pad_and_crop(x, 4))\n",
        "        x = cutout_numpy(x)\n",
        "        return x\n",
        "\n",
        "    horizontal_flip = False\n",
        "    width_shift_range = 0.0\n",
        "    height_shift_range = 0.0\n",
        "    epochs = 300\n",
        "  \n",
        "else:\n",
        "    def preprocessing_function(x: np.ndarray) -> np.ndarray:\n",
        "        return x\n",
        "    epochs = 200\n",
        "    width_shift_range = 0.125\n",
        "    height_shift_range = 0.125\n",
        "    horizontal_flip = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "56AvWfTKCuBG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "13fc4249-fc8b-4899-cf48-676504abf4e1"
      },
      "cell_type": "code",
      "source": [
        "CLASS_LABELS = np.array(['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
        "\n",
        "train_set_size = x_train.shape[0]\n",
        "# idx = 1000\n",
        "idx = np.random.randint(train_set_size)\n",
        "# idx = 2395\n",
        "label = CLASS_LABELS[y_train[idx, :].astype(bool)]\n",
        "plt.imshow(x_train[idx, :, :, :])\n",
        "plt.title(label)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,\"['deer']\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFZCAYAAAARqQ0OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f234388eac8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "dcDHEgy6Cv_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "0d6980e2-0d30-4823-a3da-9c34c32a69a1"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(preprocessing_function(x_train[idx, :, :, :]))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2343829240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f234ada3208>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "hUiPj-S-yHT0",
        "colab_type": "code",
        "outputId": "df0bc8b5-9f23-4498-fdb4-fe478190cb12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        }
      },
      "cell_type": "code",
      "source": [
        "if use_tpu:\n",
        "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    using_single_core = False\n",
        "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "    strategy = tf.contrib.tpu.TPUDistributionStrategy(tpu_cluster_resolver, using_single_core=using_single_core)\n",
        "    model = tf.contrib.tpu.keras_to_tpu_model(model, strategy=strategy)\n",
        "\n",
        "train_data = ImageDataGenerator(featurewise_center=True, \n",
        "                                featurewise_std_normalization=True, \n",
        "                                width_shift_range=width_shift_range, \n",
        "                                height_shift_range=height_shift_range, \n",
        "                                horizontal_flip=True, \n",
        "                                preprocessing_function=preprocessing_function)\n",
        "validation_data = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "test_data = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "\n",
        "for data in (train_data, validation_data, test_data):\n",
        "    data.fit(x_train)\n",
        "\n",
        "learning_rate_callback = LearningRateScheduler(partial(getitem, tuple(take(epochs, concat(repeat(0.1, 60), repeat(0.02, 60), repeat(0.004, 40), repeat(0.0008))))))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
        "callbacks = [gdcp, learning_rate_callback]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.37.240.170:8470') for TPU system metadata.\n",
            "2018-12-04 13:29:24,176 74 139790496442240: Querying Tensorflow master (b'grpc://10.37.240.170:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "2018-12-04 13:29:24,200 74 139790496442240: Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "2018-12-04 13:29:24,205 74 139790496442240: *** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "2018-12-04 13:29:24,211 74 139790496442240: *** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "2018-12-04 13:29:24,216 74 139790496442240: *** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 1841653201927113924)\n",
            "2018-12-04 13:29:24,224 74 139790496442240: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 1841653201927113924)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3469785939975192935)\n",
            "2018-12-04 13:29:24,231 74 139790496442240: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3469785939975192935)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 3524054835990595540)\n",
            "2018-12-04 13:29:24,235 74 139790496442240: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 3524054835990595540)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 14165697280433806071)\n",
            "2018-12-04 13:29:24,239 74 139790496442240: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 14165697280433806071)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 11674860323779930976)\n",
            "2018-12-04 13:29:24,245 74 139790496442240: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 11674860323779930976)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 465633645153514173)\n",
            "2018-12-04 13:29:24,248 74 139790496442240: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 465633645153514173)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 596319308975874788)\n",
            "2018-12-04 13:29:24,251 74 139790496442240: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 596319308975874788)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9826984891690188918)\n",
            "2018-12-04 13:29:24,253 74 139790496442240: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9826984891690188918)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 1221961934807360963)\n",
            "2018-12-04 13:29:24,255 74 139790496442240: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 1221961934807360963)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 13487342993285794077)\n",
            "2018-12-04 13:29:24,257 74 139790496442240: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 13487342993285794077)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5523457684201584396)\n",
            "2018-12-04 13:29:24,258 74 139790496442240: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5523457684201584396)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2489168526853703259)\n",
            "2018-12-04 13:29:24,260 74 139790496442240: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2489168526853703259)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "2018-12-04 13:29:24,263 74 139790496442240: tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.019999999552965164, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n",
            "2018-12-04 13:29:34,242 74 139790496442240: Cloning SGD {'lr': 0.019999999552965164, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.019999999552965164, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n",
            "2018-12-04 13:29:36,852 74 139790496442240: Cloning SGD {'lr': 0.019999999552965164, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WmBINcNy__EC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pa-sMNkf7lgy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_generator = train_data.flow(x_train, y_train, batch_size=batch_size)\n",
        "validation_generator = validation_data.flow(x_validation, y_validation, batch_size=batch_size)\n",
        "\n",
        "steps_per_epoch = x_train.shape[0] // batch_size\n",
        "validation_steps = x_validation.shape[0] // batch_size\n",
        "\n",
        "results = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=steps_per_epoch,\n",
        "                              epochs=epochs,\n",
        "                              initial_epoch=initial_epoch,\n",
        "                              callbacks=callbacks,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=validation_steps)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hCxz3qkRv8Qk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(results.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(results.history['loss'])\n",
        "plt.plot(results.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "emNQQUH7USVm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"{:03d}\".format(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eSrIbTe1x9jF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/modestyachts/CIFAR-10.1.git  # Recht 2018 data\n",
        "\n",
        "cifar101_data = np.load('CIFAR-10.1/datasets/cifar10.1_v6_data.npy')\n",
        "cifar101_labels = np.load('CIFAR-10.1/datasets/cifar10.1_v6_labels.npy')\n",
        "cifar101_set_size = len(cifar101_labels)\n",
        "  \n",
        "y_test = tf.keras.utils.to_categorical(cifar101_labels)\n",
        "x_test = cifar101_data / 255\n",
        "# test_x = cifar101_data.reshape(cifar101_set_size, 3, 32, 32).transpose(0, 2, 3, 1) / 255\n",
        "# test_y =\n",
        "# print(test_data.flow(test_x, test_y))\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcZOvhvpwQLj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_set_size = x_test.shape[0]\n",
        "idx = np.random.randint(test_set_size)\n",
        "# idx = 1113\n",
        "label = CLASS_LABELS[y_test[idx, :].astype(bool)]\n",
        "tit = \"{}: {}\".format(idx, label)\n",
        "plt.figure(figsize=(3,4))\n",
        "plt.imshow(x_test[idx, :, :, :])\n",
        "plt.title(tit)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nyS6TwZniZSa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(x=x_test, y=y_test)\n",
        "logger.info(\"Loss={}, acc={}\".format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4VBIZMUaMzpU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x=x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-jk07ETIOW3X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "_ = np.argmax(predictions, axis=1)\n",
        "Counter(_)\n",
        "Counter(cifar101_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Kylh1aKuWtb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_generator = train_data.flow(x_train, y_train, batch_size=batch_size)\n",
        "validation_generator = validation_data.flow(x_validation, y_validation, batch_size=batch_size)\n",
        "test_generator = test_data.flow(x_test, y_test, batch_size=batch_size)\n",
        "\n",
        "loss, acc = model.evaluate_generator(train_generator)\n",
        "logger.info(\"Train: Loss={}, acc={}\".format(loss, acc))\n",
        "\n",
        "loss, acc = model.evaluate_generator(validation_generator)\n",
        "logger.info(\"Validation: Loss={}, acc={}\".format(loss, acc))\n",
        "\n",
        "loss, acc = model.evaluate_generator(test_generator)\n",
        "logger.info(\"Test: Loss={}, acc={}\".format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "We2C1GXUWeVP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint_dir \n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "print(latest)\n",
        "!ls -ltra $checkpoint_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r5vBJMBC5HUR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# with open('./results/history.pickle', 'wb') as f:\n",
        "#     pickle.dump(results.history, f)\n",
        "\n",
        "# save_model(model, './results/model.h5')\n",
        "# del model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}