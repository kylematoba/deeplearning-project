{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_wide_res_net_matoba.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kylematoba/deeplearning-project/blob/master/keras_wide_res_net_matoba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fr2z4dXiyJfj",
        "colab_type": "code",
        "outputId": "cc25c790-1601-43b5-ff3b-9a8548ce8252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# A heavily modified version of https://github.com/tail-island/try-wide-residual-net\n",
        "!pip3 install funcy\n",
        "!pip3 install tqdm\n",
        "# !pip3 install tensorboard\n",
        "# !pip3 install npm\n",
        "# !pip3 install tensorboardcolab\n",
        "\n",
        "# !pip3 install pydot\n",
        "# !pip3 install pydot_ng\n",
        "# !pip3 install pydotplus\n",
        "# !pip3 install graphviz"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: funcy in /usr/local/lib/python3.6/dist-packages (1.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VTbQLEe3sTUv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls\n",
        "# from tensorboardcolab import *\n",
        "# tbc = TensorBoardColab()\n",
        "# tbc = TensorBoardColab(startup_waiting_time=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_MvMJmyKEekN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import pickle\n",
        "import copy\n",
        "import logging\n",
        "\n",
        "from typing import List, Tuple\n",
        "from operator import getitem, attrgetter\n",
        "from collections import namedtuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.layers import Activation, Add, BatchNormalization, Conv2D, Dense, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model, save_model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "# from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from tqdm import tqdm\n",
        "from funcy import concat, identity, juxt, partial, rcompose, repeat, repeatedly, take\n",
        "\n",
        "# from google.colab import drive\n",
        "import google.colab\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hnbyYOOQH4po",
        "colab_type": "code",
        "outputId": "88fbbf31-1d43-4cc5-a5c8-528f95b102bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "FORMAT = \"%(asctime)s %(process)s %(thread)s: %(message)s\"\n",
        "logging.basicConfig(level=logging.DEBUG, format=FORMAT, stream=sys.stdout)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "environ_dict = dict(os.environ)\n",
        "use_tpu = 'COLAB_TPU_ADDR' in environ_dict.keys()\n",
        "\n",
        "logger.info(sys.version)\n",
        "logger.info(\"{}\".format(\"Running in ipython\" if 'ipykernel' in sys.modules else \"\"))\n",
        "logger.info(\"Numpy version {}\".format(np.__version__))\n",
        "logger.info(\"TensorFlow version {}\".format(tf.__version__))\n",
        "logger.info(\"Keras version {}\".format(keras.__version__))\n",
        "if use_tpu:\n",
        "    logger.info(\"Running on TPU\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-01 08:29:52,368 60 140567285913472: 3.6.7 (default, Oct 22 2018, 11:32:17) \n",
            "[GCC 8.2.0]\n",
            "2018-12-01 08:29:52,370 60 140567285913472: Running in ipython\n",
            "2018-12-01 08:29:52,372 60 140567285913472: Numpy version 1.14.6\n",
            "2018-12-01 08:29:52,374 60 140567285913472: TensorFlow version 1.12.0\n",
            "2018-12-01 08:29:52,376 60 140567285913472: Keras version 2.2.4\n",
            "2018-12-01 08:29:52,377 60 140567285913472: Running on TPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V6DGhtaGbv5n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tt6CEfLNINuh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# mount_loc = '/content/gdrive'\n",
        "# force_remount = True\n",
        "# google.colab.drive.mount(mount_loc, force_remount=force_remount)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZqbC3tFLfa0y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !ls gdrive/'My Drive'\n",
        "# os.chdir('./gdrive/My Drive')\n",
        "# !pwd\n",
        "# os.listdir('./')\n",
        "# !cd gdrive/'My Drive'\n",
        "# !ls ./\n",
        "# # !ls $mount_loc/'My Drive'\n",
        "# # !mv $mount_loc/'My Drive' $mount_loc/my_drive\n",
        "# my_drive = os.path.join(mount_loc, 'My\\ Drive')\n",
        "# local_home = \"./local_home\"\n",
        "# os.makedirs(local_home, exist_ok=True)\n",
        "# symlink_name = os.path.join(mount_loc, 'my_drive')\n",
        "# # symlink_name = local_home\n",
        "# # !ln -s $my_drive $symlink_name\n",
        "# # !cd $symlink_name\n",
        "# !cd $my_drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hs0gqQGobTI5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # !ls $my_drive\n",
        "# !cd $my_drive\n",
        "# !ls\n",
        "# # !ls \n",
        "# # !ls ./local_home\n",
        "# # !ls $my_drive\n",
        "# # symlink_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k8-ioHknZHoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed2ded76-9732-48eb-80a9-07c194d8040e"
      },
      "cell_type": "code",
      "source": [
        "# model_name = 'wide_resnet_matoba'\n",
        "# mount_loc = './local_home/my_drive'\n",
        "# mount_loc = os.path.join(local_home, symlink_name)\n",
        "# checkpoint_dir = os.path.join(my_drive, model_name)\n",
        "# checkpoint_dir = os.path.join('./', model_name)\n",
        "# logger.info(\"Creating checkpoint location {}\".format(checkpoint_dir))\n",
        "# os.makedirs(checkpoint_dir, exist_ok=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-01 08:30:01,357 60 140567285913472: Creating checkpoint location ./wide_resnet_matoba\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lzcguFhGyByy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def download_data() -> None:\n",
        "    url = 'http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'\n",
        "    shutil.copytree(keras.utils.data_utils.get_file('cifar-10-batches-py', origin=url, untar=True), './data')\n",
        "\n",
        "    \n",
        "def load_batch(batch_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    with open(batch_path, 'rb') as f:\n",
        "        batch = pickle.load(f, encoding='bytes')\n",
        "    data_np = np.array(batch[b'data'])\n",
        "    labels_np = np.array(batch[b'labels'])\n",
        "    batch_data = data_np.reshape(data_np.shape[0], 3, 32, 32).transpose(0, 2, 3, 1) / 255\n",
        "    batch_labels = keras.utils.to_categorical(labels_np)\n",
        "    return (batch_data, batch_labels)\n",
        "\n",
        "\n",
        "def load_batches(paths: List[str]):\n",
        "    return tuple(map(np.concatenate, zip(*map(load_batch, paths))))\n",
        "\n",
        "\n",
        "def load_data(data_path='./data') -> Tuple[np.ndarray, np.ndarray]:\n",
        "    if not os.path.exists('./data'):\n",
        "        download_data()\n",
        "    paths = sorted(map(attrgetter('path'), filter(lambda directory_entry: directory_entry.name.startswith('data_batch_'), os.scandir(data_path))))\n",
        "    xy_train = load_batches(paths)\n",
        "    xy_validation = load_batch('{0}/test_batch'.format(data_path))\n",
        "    return (xy_train, xy_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H6QAKVLytND7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# if not os.path.exists('./data'):\n",
        "#     download_data()\n",
        "\n",
        "# data_path='./data'\n",
        "# paths = sorted(map(attrgetter('path'), filter(lambda directory_entry: directory_entry.name.startswith('data_batch_'), os.scandir(data_path))))\n",
        "# # print(paths)\n",
        "\n",
        "\n",
        "# batch_path = paths[0]\n",
        "# with open(batch_path, 'rb') as f:\n",
        "#     batch = pickle.load(f, encoding='bytes')\n",
        "# d = batch[b'data']\n",
        "# l = batch[b'labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QwfLMkmHx2iO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def computational_graph(class_size):\n",
        "    def ljuxt(*fs):\n",
        "        return rcompose(juxt(*fs), list)\n",
        "\n",
        "    def batch_normalization():\n",
        "        return BatchNormalization()\n",
        "\n",
        "    def relu():\n",
        "        return Activation('relu')\n",
        "\n",
        "    def conv(filter_size, kernel_size, stride_size=1):\n",
        "        return Conv2D(filter_size, kernel_size, strides=stride_size, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(0.0005), use_bias=False)\n",
        "\n",
        "    def add():\n",
        "        return Add()\n",
        "\n",
        "    def global_average_pooling():\n",
        "        return GlobalAveragePooling2D()\n",
        "\n",
        "    def dense(unit_size, activation):\n",
        "        return Dense(unit_size, activation=activation, kernel_regularizer=l2(0.0005))\n",
        "\n",
        "    # Define WRN-28-10.\n",
        "    def first_residual_unit(filter_size, stride_size):\n",
        "        return rcompose(batch_normalization(),\n",
        "                        relu(),\n",
        "                        ljuxt(rcompose(conv(filter_size, 3, stride_size),\n",
        "                                       batch_normalization(),\n",
        "                                       relu(),\n",
        "                                       conv(filter_size, 3, 1)),\n",
        "                              rcompose(conv(filter_size, 1, stride_size))),\n",
        "                        add())\n",
        "\n",
        "    def residual_unit(filter_size):\n",
        "        return rcompose(ljuxt(rcompose(batch_normalization(),\n",
        "                                       relu(),\n",
        "                                       conv(filter_size, 3),\n",
        "                                       batch_normalization(),\n",
        "                                       relu(),\n",
        "                                       conv(filter_size, 3)),\n",
        "                              identity),\n",
        "                        add())\n",
        "\n",
        "    def residual_block(filter_size, stride_size, unit_size):\n",
        "        return rcompose(first_residual_unit(filter_size, stride_size),\n",
        "                        rcompose(*repeatedly(partial(residual_unit, filter_size), unit_size - 1)))\n",
        "\n",
        "    k = 10\n",
        "    n =  4\n",
        "\n",
        "    return rcompose(conv(16, 3),\n",
        "                    residual_block(16 * k, 1, n),\n",
        "                    residual_block(32 * k, 2, n),\n",
        "                    residual_block(64 * k, 2, n),\n",
        "                    batch_normalization(),\n",
        "                    relu(),\n",
        "                    global_average_pooling(),\n",
        "                    dense(class_size, 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aAKWy_dh1qf5",
        "colab_type": "code",
        "outputId": "a549a8aa-20cf-40ce-bfa6-7bdca423bc0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 200\n",
        "checkpoint_period = 5\n",
        "\n",
        "(x_train, y_train), (x_validation, y_validation) = load_data()\n",
        "# print(x_train.shape)\n",
        "# print(x_validation.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wg1EWbZKhK3m",
        "colab_type": "code",
        "outputId": "30117752-6b7a-485e-ca7e-9855abad145f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "cell_type": "code",
      "source": [
        "CLASS_LABELS = np.array(['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'forse', 'ship', 'truck'])\n",
        "\n",
        "train_set_size = x_train.shape[0]\n",
        "# idx = 1000\n",
        "idx = np.random.randint(train_set_size)\n",
        "label = CLASS_LABELS[y_train[idx, :].astype(bool)]\n",
        "plt.imshow(x_train[idx, :, :, :])\n",
        "plt.title(label)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,\"['deer']\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFZCAYAAAARqQ0OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fd827670470>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "tHLJ9tCaa7JH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9a7e7906-e135-4177-b0ba-0d393119d43d"
      },
      "cell_type": "code",
      "source": [
        "# checkpoint_dir = checkpoint_dir\n",
        "# checkpoint_pattern = \"{epoch:03d}.ckpt\"\n",
        "# checkpoint_fullfile = os.path.join(checkpoint_dir, checkpoint_pattern)\n",
        "# logger.info(checkpoint_fullfile)\n",
        "# checkpoint_path = \"checkpoints/{epoch:03d}.ckpt\"\n",
        "# checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "# logger.info(\"Creating checkpoint location {}\".format())\n",
        "# os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "# if latest is not None:  # this is actually the better way to do it by far, as it doesn't entail the costly process of re-loading inside of the loop\n",
        "#     logger.info(\"Restoring model from {}\".format(latest))\n",
        "#     model.load_weights(latest)\n",
        "# print(latest)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-11-30 08:00:39,028 59 140669153396608: ./wide_resnet_matoba/{epoch:03d}.ckpt\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z4yzSHFZpeRa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def good_policies():\n",
        "    \"\"\"AutoAugment policies found on analysis.\"\"\"\n",
        "    exp0_0 = [\n",
        "      [('flip_lr', 0.5, 5)],\n",
        "      [('TranslateY', 0.5, 5)],\n",
        "      [('TranslateX', 0.5, 5)],\n",
        "      [('ShearY', 0.5, 5)],\n",
        "      [('Solarize', 0.5, 5)],\n",
        "      [('Rotate', 0.5, 5)]\n",
        "    ]\n",
        "    return  exp0_0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HVHi7FwKhYts",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ROOT = os.path.abspath('.')\n",
        "LOG_DIR = os.path.join(ROOT, 'log')\n",
        "\n",
        "# Represents a Folder or File in your Google Drive\n",
        "GDriveItem = namedtuple('GDriveItem', ['name', 'fid'])\n",
        "\n",
        "# Represents Epoch information as returned from keras\n",
        "EpochData = namedtuple('EpochData', ['epoch', 'losses'])\n",
        "\n",
        "\n",
        "class GDriveSync:\n",
        "    \"\"\"\n",
        "    Simple up/downloading functionality to move local files into the cloud and vice versa.\n",
        "    Provides progress bars for both up- and download.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        auth.authenticate_user()  # prompt the user to access his Google Drive via the API\n",
        "\n",
        "        self.drive_service = build('drive', 'v3')\n",
        "        self.default_folder = self.find_items('Colab Notebooks')[0]\n",
        "\n",
        "    def find_items(self, name):\n",
        "        \"\"\"\n",
        "        Find folders or files based on their name. This always searches the full Google Drive tree!\n",
        "        :param name: Term to be searched. All files containing this search term are returned.\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        folder_list = self.drive_service.files().list(q='name contains \"%s\"' % name).execute()\n",
        "        folders = []\n",
        "        for folder in folder_list['files']:\n",
        "            folders.append(GDriveItem(folder['name'], folder['id']))\n",
        "\n",
        "        return folders\n",
        "\n",
        "    def upload_file_to_folder(self, local_file, folder=None):\n",
        "        \"\"\"\n",
        "        Upload a local file, optionally to a specific folder in Google Drive\n",
        "        :param local_file: Path to the local file\n",
        "        :param folder: (Option) GDriveItem which should be the parent.\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        if folder is not None:\n",
        "            assert type(folder)==GDriveItem\t\n",
        "\n",
        "        file_metadata = {\n",
        "            'title': local_file,\n",
        "            'name': local_file\n",
        "        }\n",
        "\n",
        "        if folder is not None:\n",
        "            file_metadata['parents'] = [folder.fid]\n",
        "\n",
        "        media = MediaFileUpload(local_file, resumable=True)\n",
        "        created = self.drive_service.files().create(body=file_metadata,\n",
        "                                                    media_body=media,\n",
        "                                                    fields='id')\n",
        "        response = None\n",
        "        last_progress = 0\n",
        "\n",
        "        if folder is not None:\n",
        "            d = 'Uploading file %s to folder %s' % (local_file, folder.name)\n",
        "        else:\n",
        "            d = 'Uploading file %s' % local_file\n",
        "\n",
        "        pbar = tqdm(total=100, desc=d)\n",
        "        while response is None:\n",
        "            status, response = created.next_chunk()\n",
        "            if status:\n",
        "                p = status.progress() * 100\n",
        "                dp = p - last_progress\n",
        "                pbar.update(dp)\n",
        "                last_progress = p\n",
        "\n",
        "        pbar.update(100 - last_progress)\n",
        "\n",
        "    def download_file_to_folder(self, remote_file, path):\n",
        "        assert type(remote_file)==GDriveItem\n",
        "        request = self.drive_service.files().get_media(fileId=remote_file.fid)\n",
        "\n",
        "        last_progress = 0\n",
        "        pbar = tqdm(total=100, desc='Downloading file %s to %s' % (remote_file.name, path))\n",
        "\n",
        "        with open(path, 'wb') as fh:\n",
        "            downloader = MediaIoBaseDownload(fh, request)\n",
        "            done = False\n",
        "            while done is False:\n",
        "                status, done = downloader.next_chunk()\n",
        "                if status:\n",
        "                    p = status.progress() * 100\n",
        "                    dp = p - last_progress\n",
        "                    pbar.update(dp)\n",
        "                    last_progress = p\n",
        "\n",
        "        pbar.update(100 - last_progress)\n",
        "\n",
        "    def delete_file(self, file):\n",
        "        assert type(file) == GDriveItem\n",
        "        request = self.drive_service.files().delete(fileId=file.fid)\n",
        "        request.execute()\n",
        "\n",
        "\n",
        "class GDriveCheckpointer(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Keras Callback that automatically saves models into your Google Drive.\n",
        "    Outdated checkpoints are automatically deleted remotely to prevent GDrive from filling up.\n",
        "    Checkpointing is controlled by two functions:\n",
        "        compare_fn(best_epoch: EpochData, current_epoch: EpochData) -> bool\n",
        "        - If this function returns true, the current_epoch is assumed to have better performance than the older best_epoch.\n",
        "        - e.g. return best_epoch.losses['val_acc'] < current_epoch.losses['val_acc']\n",
        "        filepath_fn(epoch: EpochData) -> Union[String, None]\n",
        "        - If this function returns None, the checkpoint is skipped. This can be used to skip backing up early epochs.\n",
        "          If it returns a String path, the model is uploaded into the default GDrive folder with the given file name.\n",
        "    \"\"\"\n",
        "    def __init__(self, compare_fn, filepath_fn, save_optimizer=False):\n",
        "        assert compare_fn is not None, 'Need a compare function which gets all the losses and evaluation data of two epochs and which needs to return True if the second one is better.'\n",
        "        assert filepath_fn is not None, 'Need a function that derives a file path based on a dictionary of losses and metrics.'\n",
        "\n",
        "        super(GDriveCheckpointer, self).__init__()\n",
        "        self.saver = GDriveSync()\n",
        "        self.compare_fn = compare_fn\n",
        "        self.filepath_fn = filepath_fn\n",
        "        self.best_epoch = None\n",
        "        self.best_filename = None\n",
        "        self.save_optimizer = save_optimizer\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        l = dict(logs)\n",
        "        d = EpochData(epoch, l)\n",
        "        if self.best_epoch is None or self.compare_fn(self.best_epoch, d):\n",
        "            self.best_epoch = copy.deepcopy(d)\n",
        "            fn = self.filepath_fn(d)\n",
        "            if fn is not None and fn:\n",
        "                if self.best_filename:\n",
        "                    os.remove(self.best_filename)\n",
        "                    old_file = self.saver.find_items(self.best_filename)[0]\n",
        "                    print('Removing old cloud file %s' % old_file.name)\n",
        "                    self.saver.delete_file(old_file)\n",
        "                self.best_filename = fn\n",
        "                self._save_checkpoint()\n",
        "            else:\n",
        "                print('Skipping upload because path function returned no path.')\n",
        "        else:\n",
        "            print('No improvement.')\n",
        "\n",
        "    def _save_checkpoint(self):\n",
        "        self.model.save(self.best_filename, include_optimizer=self.save_optimizer)\n",
        "        self.saver.upload_file_to_folder(self.best_filename, self.saver.default_folder)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hfTNTdhRng3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "outputId": "49a3fa46-a822-45ff-d13c-11050e36fda3"
      },
      "cell_type": "code",
      "source": [
        "def compare(best, new):\n",
        "    return True\n",
        "\n",
        "def path(new):\n",
        "    # return 'VGG16_%s.h5' % new.losses['val_acc']\n",
        "    return str(new)\n",
        "\n",
        "  \n",
        "gdcp = GDriveCheckpointer(compare, path)\n",
        "gdcp"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-01 08:38:19,678 60 140567285913472: Making request: POST https://accounts.google.com/o/oauth2/token\n",
            "2018-12-01 08:38:19,688 60 140567285913472: Starting new HTTPS connection (1): accounts.google.com\n",
            "2018-12-01 08:38:19,737 60 140567285913472: https://accounts.google.com:443 \"POST /o/oauth2/token HTTP/1.1\" 200 None\n",
            "2018-12-01 08:38:19,748 60 140567285913472: file_cache is unavailable when using oauth2client >= 4.0.0\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    'file_cache is unavailable when using oauth2client >= 4.0.0')\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0\n",
            "2018-12-01 08:38:19,751 60 140567285913472: URL being requested: GET https://www.googleapis.com/discovery/v1/apis/drive/v3/rest\n",
            "2018-12-01 08:38:19,800 60 140567285913472: No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
            "2018-12-01 08:38:19,810 60 140567285913472: URL being requested: GET https://www.googleapis.com/drive/v3/files?q=name+contains+%22Colab+Notebooks%22&alt=json\n",
            "2018-12-01 08:38:19,812 60 140567285913472: Making request: POST https://accounts.google.com/o/oauth2/token\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.GDriveCheckpointer at 0x7fd82495f080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "hUiPj-S-yHT0",
        "colab_type": "code",
        "outputId": "3d13693f-2627-420f-e387-4584c67704d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        }
      },
      "cell_type": "code",
      "source": [
        "xshape = x_train.shape[1:]\n",
        "yshape = y_train.shape[1]\n",
        "model = Model(*juxt(identity, computational_graph(yshape))(Input(shape=xshape)))\n",
        "optimizer = SGD(momentum=0.9)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])  # nesterov=True\n",
        "# model.summary()\n",
        "\n",
        "if use_tpu:\n",
        "    TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "    using_single_core = False\n",
        "    tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "    strategy = tf.contrib.tpu.TPUDistributionStrategy(tpu_cluster_resolver, using_single_core=using_single_core)\n",
        "    model = tf.contrib.tpu.keras_to_tpu_model(model, strategy=strategy)\n",
        "\n",
        "# tensorflow.keras.utils.plot_model(model, to_file='./results/model.png')\n",
        "\n",
        "train_data = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True, width_shift_range=0.125, height_shift_range=0.125, horizontal_flip=True)\n",
        "validation_data = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "test_data = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "\n",
        "for data in (train_data, validation_data, test_data):\n",
        "    data.fit(x_train)\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_fullfile, \n",
        "                                                         save_weights_only=False,\n",
        "                                                         verbose=1, \n",
        "                                                         period=checkpoint_period)\n",
        "learning_rate_callback = LearningRateScheduler(partial(getitem, tuple(take(epochs, concat(repeat(0.1, 60), repeat(0.02, 60), repeat(0.004, 40), repeat(0.0008))))))\n",
        "# https://keras.io/callbacks/#tensorboard\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "# callbacks = [checkpoint_callback, learning_rate_callback]\n",
        "callbacks = [gdcp, learning_rate_callback]\n",
        "# checkpoint_path = tf.train.latest_checkpoint(self.model_dir)\n",
        "\n",
        "\n",
        "#         checkpoint_path = tf.train.latest_checkpoint(self.model_dir)\n",
        "#         if checkpoint_path is not None:\n",
        "#             self.saver.restore(self.session, checkpoint_path)\n",
        "# https://github.com/tensorflow/tensorflow/blob/bde19b79b3d5e0d4be679f8144acb7f06b1c83ee/tensorflow/contrib/tpu/python/tpu/keras_support.py#L2040-L2072\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "if latest is not None:  # this is actually the better way to do it by far, as it doesn't entail the costly process of re-loading inside of the loop\n",
        "    logger.info(\"Restoring model from {}\".format(latest))\n",
        "    model.load_weights(latest)\n",
        "\n",
        "    \n",
        "train_generator = train_data.flow(x_train, y_train, batch_size=batch_size)\n",
        "validation_generator = validation_data.flow(x_validation, y_validation, batch_size=batch_size)\n",
        "results = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=x_train.shape[0] // batch_size,\n",
        "                              epochs=epochs,\n",
        "                              callbacks=callbacks,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=x_validation.shape[0] // batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (b'grpc://10.32.245.146:8470') for TPU system metadata.\n",
            "2018-12-01 08:41:14,839 60 140567285913472: Querying Tensorflow master (b'grpc://10.32.245.146:8470') for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "2018-12-01 08:41:14,862 60 140567285913472: Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "2018-12-01 08:41:14,865 60 140567285913472: *** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "2018-12-01 08:41:14,870 60 140567285913472: *** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "2018-12-01 08:41:14,874 60 140567285913472: *** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 3389636593579465592)\n",
            "2018-12-01 08:41:14,882 60 140567285913472: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 3389636593579465592)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1277977227214820504)\n",
            "2018-12-01 08:41:14,889 60 140567285913472: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1277977227214820504)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 9952738596699262635)\n",
            "2018-12-01 08:41:14,895 60 140567285913472: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 9952738596699262635)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12435536490377181287)\n",
            "2018-12-01 08:41:14,902 60 140567285913472: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12435536490377181287)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4591093595895466224)\n",
            "2018-12-01 08:41:14,906 60 140567285913472: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4591093595895466224)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 17910635166728652450)\n",
            "2018-12-01 08:41:14,911 60 140567285913472: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 17910635166728652450)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 15542371731338125826)\n",
            "2018-12-01 08:41:14,915 60 140567285913472: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 15542371731338125826)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 1127846165321634719)\n",
            "2018-12-01 08:41:14,919 60 140567285913472: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 1127846165321634719)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 166085132724011373)\n",
            "2018-12-01 08:41:14,923 60 140567285913472: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 166085132724011373)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 18134456572715658007)\n",
            "2018-12-01 08:41:14,927 60 140567285913472: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 18134456572715658007)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16806311524311406038)\n",
            "2018-12-01 08:41:14,932 60 140567285913472: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16806311524311406038)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 4365771195691430323)\n",
            "2018-12-01 08:41:14,936 60 140567285913472: *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 4365771195691430323)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "2018-12-01 08:41:14,941 60 140567285913472: tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.009999999776482582, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n",
            "2018-12-01 08:41:25,794 60 140567285913472: Cloning SGD {'lr': 0.009999999776482582, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n",
            "INFO:tensorflow:Cloning SGD {'lr': 0.009999999776482582, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n",
            "2018-12-01 08:41:28,235 60 140567285913472: Cloning SGD {'lr': 0.009999999776482582, 'momentum': 0.8999999761581421, 'decay': 0.0, 'nesterov': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hCxz3qkRv8Qk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(results.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(results.history['loss'])\n",
        "plt.plot(results.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eSrIbTe1x9jF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/modestyachts/CIFAR-10.1.git  # Recht 2018 data\n",
        "\n",
        "cifar101_data = np.load('CIFAR-10.1/datasets/cifar10.1_v6_data.npy')\n",
        "cifar101_labels = np.load('CIFAR-10.1/datasets/cifar10.1_v6_labels.npy')\n",
        "cifar101_set_size = len(cifar101_labels)\n",
        "  \n",
        "y_test = keras.utils.to_categorical(cifar101_labels)\n",
        "x_test = cifar101_data / 255\n",
        "# test_x = cifar101_data.reshape(cifar101_set_size, 3, 32, 32).transpose(0, 2, 3, 1) / 255\n",
        "# test_y =\n",
        "# print(test_data.flow(test_x, test_y))\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcZOvhvpwQLj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_set_size = x_test.shape[0]\n",
        "idx = np.random.randint(test_set_size)\n",
        "# idx = 1113\n",
        "label = CLASS_LABELS[y_test[idx, :].astype(bool)]\n",
        "tit = \"{}: {}\".format(idx, label)\n",
        "plt.figure(figsize=(3,4))\n",
        "plt.imshow(x_test[idx, :, :, :])\n",
        "plt.title(tit)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nyS6TwZniZSa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(x=x_test, y=y_test)\n",
        "logger.info(\"Loss={}, acc={}\".format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4VBIZMUaMzpU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x=x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-jk07ETIOW3X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "_ = np.argmax(predictions, axis=1)\n",
        "Counter(_)\n",
        "Counter(cifar101_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Kylh1aKuWtb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_generator = train_data.flow(x_train, y_train, batch_size=batch_size)\n",
        "validation_generator = validation_data.flow(x_validation, y_validation, batch_size=batch_size)\n",
        "test_generator = test_data.flow(x_test, y_test, batch_size=batch_size)\n",
        "\n",
        "loss, acc = model.evaluate_generator(train_generator)\n",
        "logger.info(\"Train: Loss={}, acc={}\".format(loss, acc))\n",
        "\n",
        "loss, acc = model.evaluate_generator(validation_generator)\n",
        "logger.info(\"Validation: Loss={}, acc={}\".format(loss, acc))\n",
        "\n",
        "loss, acc = model.evaluate_generator(test_generator)\n",
        "logger.info(\"Test: Loss={}, acc={}\".format(loss, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "We2C1GXUWeVP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint_dir \n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "print(latest)\n",
        "!ls -ltra $checkpoint_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r5vBJMBC5HUR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# with open('./results/history.pickle', 'wb') as f:\n",
        "#     pickle.dump(results.history, f)\n",
        "\n",
        "# save_model(model, './results/model.h5')\n",
        "# del model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}